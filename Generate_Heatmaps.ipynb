{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean    \n",
    "import pickle\n",
    "import numpy as np\n",
    "from skimage import novice\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from guppy import hpy\n",
    "from PIL import ImageFile\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory profiling\n",
    "hp = hpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DISTANCE_SMOOTHING = 0.1\n",
    "EMOTION_SCALING = 200.0\n",
    "RADIUS_SCALING = 0.1\n",
    "FROM_CENTER_SMOOTHING = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training phase paths\n",
    "TRAIN_BASE_PATH = 'Data/Train'\n",
    "TRAIN_FACES_BASE_PATH = 'Data/Indi-Face-Predictions/faces/Train'\n",
    "\n",
    "POSITIVE_TRAIN_BASE_PATH = os.path.join(TRAIN_BASE_PATH, 'Positive')\n",
    "POSITIVE_TRAIN_FACES_BASE_PATH = os.path.join(TRAIN_FACES_BASE_PATH, 'positive', 'positive')\n",
    "NEGATIVE_TRAIN_BASE_PATH = os.path.join(TRAIN_BASE_PATH, 'Negative')\n",
    "NEGATIVE_TRAIN_FACES_BASE_PATH = os.path.join(TRAIN_FACES_BASE_PATH, 'negative', 'negative')\n",
    "NEUTRAL_TRAIN_BASE_PATH = os.path.join(TRAIN_BASE_PATH, 'Neutral')\n",
    "NEUTRAL_TRAIN_FACES_BASE_PATH = os.path.join(TRAIN_FACES_BASE_PATH, 'neutral', 'neutral')\n",
    "\n",
    "# Training phase paths\n",
    "TRAIN_DUMP_BASE_PATH = 'Data/Heatmaps/TrainGaussianNormalizedCenter'\n",
    "TRAIN_DUMP_FACES_BASE_PATH = 'Data/Notebooks/Indi-Face-Predictions/faces/Heatmaps'\n",
    "\n",
    "POSITIVE_DUMP_TRAIN_BASE_PATH = os.path.join(TRAIN_DUMP_BASE_PATH, 'Positive')\n",
    "POSITIVE_DUMP_TRAIN_FACES_BASE_PATH = os.path.join(TRAIN_DUMP_FACES_BASE_PATH, 'positiveLinear')\n",
    "NEGATIVE_DUMP_TRAIN_BASE_PATH = os.path.join(TRAIN_DUMP_BASE_PATH, 'Negative')\n",
    "NEGATIVE_DUMP_TRAIN_FACES_BASE_PATH = os.path.join(TRAIN_DUMP_FACES_BASE_PATH, 'negativeLinear')\n",
    "NEUTRAL_DUMP_TRAIN_BASE_PATH = os.path.join(TRAIN_DUMP_BASE_PATH, 'Neutral')\n",
    "NEUTRAL_DUMP_TRAIN_FACES_BASE_PATH = os.path.join(TRAIN_DUMP_FACES_BASE_PATH, 'neutralLinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data paths\n",
    "TEST_BASE_PATH = 'Data/TestImages_Latest'\n",
    "TEST_FACES_BASE_PATH = 'Data/Test'\n",
    "\n",
    "POSITIVE_TEST_BASE_PATH = os.path.join(TEST_BASE_PATH, 'Positive')\n",
    "POSITIVE_TEST_FACES_BASE_PATH = os.path.join(TEST_FACES_BASE_PATH, 'Positive')\n",
    "NEGATIVE_TEST_BASE_PATH = os.path.join(TEST_BASE_PATH, 'Negative')\n",
    "NEGATIVE_TEST_FACES_BASE_PATH = os.path.join(TEST_FACES_BASE_PATH, 'Negative')\n",
    "NEUTRAL_TEST_BASE_PATH = os.path.join(TEST_BASE_PATH, 'Neutral')\n",
    "NEUTRAL_TEST_FACES_BASE_PATH = os.path.join(TEST_FACES_BASE_PATH, 'Neutral')\n",
    "\n",
    "# Validate Dump paths \n",
    "TEST_DUMP_BASE_PATH = 'Data/Heatmaps/Test-Center-Normed'\n",
    "TEST_DUMP_FACES_BASE_PATH = 'Data/Indi-Face-Predictions/faces/Heatmaps'\n",
    "\n",
    "POSITIVE_DUMP_TEST_BASE_PATH = os.path.join(TEST_DUMP_BASE_PATH, 'Positive')\n",
    "POSITIVE_DUMP_TEST_FACES_BASE_PATH = os.path.join(TEST_DUMP_FACES_BASE_PATH, 'positive')\n",
    "NEGATIVE_DUMP_TEST_BASE_PATH = os.path.join(TEST_DUMP_BASE_PATH, 'Negative')\n",
    "NEGATIVE_DUMP_TEST_FACES_BASE_PATH = os.path.join(TEST_DUMP_FACES_BASE_PATH, 'negative')\n",
    "NEUTRAL_DUMP_TEST_BASE_PATH = os.path.join(TEST_DUMP_BASE_PATH, 'Neutral')\n",
    "NEUTRAL_DUMP_TEST_FACES_BASE_PATH = os.path.join(TEST_DUMP_FACES_BASE_PATH, 'neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data paths\n",
    "VALIDATE_BASE_PATH = 'Data/Validate'\n",
    "VALIDATE_FACES_BASE_PATH = 'Data/Indi-Face-Predictions/faces/Validate'\n",
    "\n",
    "POSITIVE_VALIDATE_BASE_PATH = os.path.join(VALIDATE_BASE_PATH, 'Positive')\n",
    "POSITIVE_VALIDATE_FACES_BASE_PATH = os.path.join(VALIDATE_FACES_BASE_PATH, 'Positive')\n",
    "NEGATIVE_VALIDATE_BASE_PATH = os.path.join(VALIDATE_BASE_PATH, 'Negative')\n",
    "NEGATIVE_VALIDATE_FACES_BASE_PATH = os.path.join(VALIDATE_FACES_BASE_PATH, 'Negative')\n",
    "NEUTRAL_VALIDATE_BASE_PATH = os.path.join(VALIDATE_BASE_PATH, 'Neutral')\n",
    "NEUTRAL_VALIDATE_FACES_BASE_PATH = os.path.join(VALIDATE_FACES_BASE_PATH, 'Neutral')\n",
    "\n",
    "# Validate Dump paths \n",
    "VALIDATE_DUMP_BASE_PATH = 'Data/Heatmaps/ValidateGaussianNormalizedCenter'\n",
    "VALIDATE_DUMP_FACES_BASE_PATH = 'Data/Indi-Face-Predictions/faces/Heatmaps'\n",
    "\n",
    "POSITIVE_DUMP_VALIDATE_BASE_PATH = os.path.join(VALIDATE_DUMP_BASE_PATH, 'Positive')\n",
    "POSITIVE_DUMP_VALIDATE_FACES_BASE_PATH = os.path.join(VALIDATE_DUMP_FACES_BASE_PATH, 'positive')\n",
    "NEGATIVE_DUMP_VALIDATE_BASE_PATH = os.path.join(VALIDATE_DUMP_BASE_PATH, 'Negative')\n",
    "NEGATIVE_DUMP_VALIDATE_FACES_BASE_PATH = os.path.join(VALIDATE_DUMP_FACES_BASE_PATH, 'negative')\n",
    "NEUTRAL_DUMP_VALIDATE_BASE_PATH = os.path.join(VALIDATE_DUMP_BASE_PATH, 'Neutral')\n",
    "NEUTRAL_DUMP_VALIDATE_FACES_BASE_PATH = os.path.join(VALIDATE_DUMP_FACES_BASE_PATH, 'neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_FACES_PATH = 'Data/Paper/pics/faces/'\n",
    "PAPER_PICS_PATH = 'Data/Paper/pics/pics/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get center and radius using rectangular points\n",
    "def get_center_and_radius(top_left, bottom_right):\n",
    "    x0, y0 = top_left\n",
    "    x1, y1 = bottom_right\n",
    "    # Mid-point of the diagonal gives the center\n",
    "    center = ((x0 + x1) / 2.0, (y0 + y1) / 2.0)\n",
    "    \n",
    "    # Approximation of distance as 1 / 2 the distance  \n",
    "    # between diagonal vertices of the rectangle (~square)\n",
    "    diameter = euclidean(top_left, bottom_right)\n",
    "    radius = diameter / 2.0\n",
    "    \n",
    "    return (center, radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test center and radius function\n",
    "print get_center_and_radius((0, 3), (3, 0))   #((1.5, 1.5), 2.12)\n",
    "print get_center_and_radius((0, 3), (4, 0))   #((2.0, 1.5), 2.50)\n",
    "print get_center_and_radius((2, 18), (14, 7)) #((8.0, 12.5), 8.14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_emotion_vectors(vectors):\n",
    "    # Average the five vectors and obtain scores for +ve, -ve and neutral emotions\n",
    "    summation = np.zeros(7)\n",
    "    for i in xrange(5):\n",
    "        emo_vector = vectors[i][0]\n",
    "        summation += emo_vector\n",
    "    average = summation / 5.0\n",
    "    \n",
    "    positive = average[3]\n",
    "    negative = np.sum(average[:3] + average[5]) / 4.0\n",
    "    neutral = average[4]\n",
    "    \n",
    "    # Return in alphabetical order to make it easier to remember\n",
    "    return (negative, neutral, positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_face_heatmaps(face_heatmaps, path_to_save):\n",
    "    heatmap_size = face_heatmaps[0].shape\n",
    "    combination = np.zeros(heatmap_size)\n",
    "    for hmap in face_heatmaps:\n",
    "        combination += hmap\n",
    "    plt.imsave(path_to_save + '.png', combination.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_linear(width, height, center=None, radius=3):\n",
    "    \n",
    "    x = np.arange(0, width, 1, float)\n",
    "    y = np.arange(0, height, 1, float)\n",
    "    y.shape = (height, 1)\n",
    "    \n",
    "    if center is None:\n",
    "        x0 = width // 2\n",
    "        y0 = height // 2\n",
    "    else:\n",
    "        x0, y0 = center\n",
    "    distance = (x - x0) ** 2 + (y - y0) ** 2\n",
    "    linear = (0.1 * abs(x - x0)) + (0.1 * abs(y - y0))\n",
    "    inverse_linear = 1.0 / linear\n",
    "    inverse_linear[np.isinf(inverse_linear)] = 1.0\n",
    "    return inverse_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gaussian(width, height, center=None, fwhm = 3):\n",
    "    \"\"\" Make a square gaussian kernel.\n",
    "    fwhm is full-width-half-maximum, which\n",
    "    can be thought of as an effective radius.\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.arange(0, width, 1, float)\n",
    "    y = np.arange(0, height, 1, float)\n",
    "    y.shape = (height, 1)\n",
    "    \n",
    "    if center is None:\n",
    "        x0 = y0 = size // 2\n",
    "    else:\n",
    "        x0, y0 = center\n",
    "    \n",
    "    return np.exp(-4*np.log(2) * ((DISTANCE_SMOOTHING * (x-x0)) ** 2 + (DISTANCE_SMOOTHING * (y-y0)) **2) / fwhm**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_3d_plot(numpy_array, destination, x_label, y_label, z_label):\n",
    "    print numpy_array.shape\n",
    "    fig = plt.figure()\n",
    "    xs, ys = numpy_array.shape\n",
    "\n",
    "    x = np.linspace(0, xs, xs)\n",
    "    y = np.linspace(0, ys, ys)\n",
    "    X, Y = np.meshgrid(y, x)\n",
    "    \n",
    "    print X.shape\n",
    "    print Y.shape\n",
    "    fig = plt.figure(figsize=(15, 12))\n",
    "    ax = fig.gca(projection='3d')\n",
    "    ax.plot_surface(X, Y, numpy_array, cmap='jet',linewidth=0)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_zlabel(z_label)\n",
    "    \n",
    "    plt.savefig(destination)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_image = None\n",
    "def process_pickles(id_coord_pkl, emotion_pkl, image_base_path, subimage_base_path, \n",
    "                    image_destination_base_path, subimage_destination_base_path):\n",
    "    global global_image\n",
    "    # See if the pickles are of same length\n",
    "    assert len(id_coord_pkl[0]) == len(emotion_pkl), 'Pickle length mismatch'\n",
    "    image_names = id_coord_pkl[0]\n",
    "    subimage_names = id_coord_pkl[1]\n",
    "    coordinates = id_coord_pkl[2]\n",
    "    \n",
    "    current_image = None\n",
    "    current_img_object = None\n",
    "    current_img_size = None\n",
    "    current_img_center = None\n",
    "    new_image_flag = None\n",
    "    image_heatmaps = list()\n",
    "    for i in tqdm(xrange(len(image_names))):\n",
    "        # See if it's a new sub-image or the old one\n",
    "        image_name = image_names[i]\n",
    "        \n",
    "        if image_name != current_image:\n",
    "            if current_image is not None:                \n",
    "                path_to_save = os.path.join(image_destination_base_path, current_image)\n",
    "                plt.imsave(path_to_save + '.png', combination.astype(int))\n",
    "            current_image = image_name\n",
    "            current_img_object = novice.open(os.path.join(image_base_path, current_image))\n",
    "            current_img_size = current_img_object.size\n",
    "            current_img_center = current_img_size[0] // 2, current_img_size[1] // 2\n",
    "            new_image_flag = True\n",
    "        else:\n",
    "            new_image_flag = False\n",
    "            \n",
    "        subimage_name = subimage_names[i]\n",
    "        # subimage_object = novice.open(os.path.join(subimage_base_path, subimage_name))\n",
    "        # subimage_object_size = subimage_object.size\n",
    "            \n",
    "        subimage_coordinates = coordinates[i]\n",
    "        y1 = subimage_coordinates[0]\n",
    "        y0 = subimage_coordinates[1]\n",
    "        x0 = subimage_coordinates[2]\n",
    "        x1 = subimage_coordinates[3]\n",
    "        \n",
    "#         subimage_size_calculated = (abs(x1 - x0), abs(y1 - y0))\n",
    "#         Sanity Check: The size of the subimage must be the same as in the pickle\n",
    "#         assert subimage_object_size == subimage_size_calculated, '''Image on disk: {0}. \n",
    "#         Image in pickle: {1}.\n",
    "#         Index: {2}. \n",
    "#         Pickle Image: {3}\n",
    "#         Disk Image: {4}\n",
    "#         Main Image: {5}\n",
    "#         Coords: {6}'''.format(subimage_object_size, subimage_size_calculated, i, subimage_name, \n",
    "#                              os.path.join(subimage_base_path, subimage_name), current_image,\n",
    "#                              subimage_coordinates)\n",
    "        \n",
    "        center, radius = get_center_and_radius((x0, y1), (x1, y0))\n",
    "        distance_from_img_center = euclidean(center, current_img_center)\n",
    "#         print 'Center:', center, 'Image Center:', current_img_center\n",
    "#         print 'Distance:', distance_from_img_center\n",
    "        distance_from_center_smoothed = FROM_CENTER_SMOOTHING * distance_from_img_center\n",
    "        distance_from_center_inverse = 1.0 / distance_from_center_smoothed\n",
    "        scaled_radius = RADIUS_SCALING * radius\n",
    "        emotion_vectors = emotion_pkl[i]\n",
    "        (negative, positive, neutral) = combine_emotion_vectors(emotion_vectors)\n",
    "        \n",
    "        # Now we have everything we need to construct a heatmap\n",
    "        # print 'positive: ', positive, 'negative: ', negative, 'neutral: ', neutral, 'center:', center, 'radius: ', radius \n",
    "#         pmap = distance_from_center_inverse * EMOTION_SCALING * positive * make_gaussian(current_img_size[0], current_img_size[1], center, scaled_radius)\n",
    "#         omap = distance_from_center_inverse * EMOTION_SCALING * neutral * make_gaussian(current_img_size[0], current_img_size[1], center, scaled_radius)\n",
    "#         nmap = distance_from_center_inverse * EMOTION_SCALING * negative * make_gaussian(current_img_size[0], current_img_size[1], center, scaled_radius)\n",
    "        \n",
    "        pmap = EMOTION_SCALING * positive * make_gaussian(current_img_size[0], current_img_size[1], center, scaled_radius)\n",
    "        omap = EMOTION_SCALING * neutral * make_gaussian(current_img_size[0], current_img_size[1], center, scaled_radius)\n",
    "        nmap = EMOTION_SCALING * negative * make_gaussian(current_img_size[0], current_img_size[1], center, scaled_radius)\n",
    "        \n",
    "        \n",
    "        # Contruct an image using the heatmap\n",
    "        # R: Negative, G: Neutral, B: Positive\n",
    "        image = np.dstack((nmap, omap, pmap))\n",
    "        plt.imsave(os.path.join(subimage_destination_base_path, subimage_name + '_int_pmap.png'), pmap.astype(int))\n",
    "        plt.imsave(os.path.join(subimage_destination_base_path, subimage_name + '_int_omap.png'), omap.astype(int))\n",
    "        plt.imsave(os.path.join(subimage_destination_base_path, subimage_name + '_int_nmap.png'), nmap.astype(int))\n",
    "        plt.imsave(os.path.join(subimage_destination_base_path, subimage_name + '_combined.png'), image.astype(int))\n",
    "        \n",
    "        # create_3d_plot(pmap, os.path.join(subimage_destination_base_path, subimage_name + '_gaussian_pos.png'), 'Width', 'Height', 'Positive Emotion')\n",
    "        # create_3d_plot(nmap, os.path.join(subimage_destination_base_path, subimage_name + '_gaussian_neg.png'), 'Width', 'Height', 'Negative Emotion')\n",
    "        # create_3d_plot(omap, os.path.join(subimage_destination_base_path, subimage_name + '_gaussian_neu.png'), 'Width', 'Height', 'Neutral Emotion')\n",
    "        if new_image_flag:\n",
    "            combination = image\n",
    "            #print combination\n",
    "        else:\n",
    "            combination += image\n",
    "            #print combination\n",
    "#         print type(image)\n",
    "#         print image.shape\n",
    "        # Write the image on to the disk and add it to the list for further processing\n",
    "        # heatmaps.append(image)\n",
    "        \n",
    "        # https://stackoverflow.com/questions/31544130/saving-an-imshow-like-image-while-preserving-resolution\n",
    "        # plt.imsave(os.path.join(subimage_destination_base_path, subimage_name + '.png'), image.astype(int))\n",
    "    \n",
    "    # Save the pickle object in the end\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use saved predictions\n",
    "Each of the pickles used below were obtained by extracting faces from the images and predicting emotions using models by [Levi and Hassner](https://www.openu.ac.il/home/hassner/projects/cnn_emotions/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_coord_pickle = pickle.load(open('positive_details_.obj', 'rb'))\n",
    "positive_emo_pickle = pickle.load(open('train_positive_predictions.pkl', 'rb'))\n",
    "\n",
    "process_pickles(positive_coord_pickle, positive_emo_pickle, POSITIVE_TRAIN_BASE_PATH, \n",
    "                POSITIVE_TRAIN_FACES_BASE_PATH, POSITIVE_DUMP_TRAIN_BASE_PATH, \n",
    "                POSITIVE_DUMP_TRAIN_FACES_BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_coord_pickle = pickle.load(open('neutral_details.obj', 'rb'))\n",
    "neutral_emo_pickle = pickle.load(open('train_neutral_predictions.pkl', 'rb'))\n",
    "\n",
    "process_pickles(neutral_coord_pickle, neutral_emo_pickle,  NEUTRAL_TRAIN_BASE_PATH, \n",
    "                NEUTRAL_TRAIN_FACES_BASE_PATH, NEUTRAL_DUMP_TRAIN_BASE_PATH, \n",
    "                NEUTRAL_DUMP_TRAIN_FACES_BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_coord_pickle = pickle.load(open('negative_details_.obj', 'rb'))\n",
    "negative_emo_pickle = pickle.load(open('train_negative_predictions.pkl', 'rb'))\n",
    "\n",
    "process_pickles(negative_coord_pickle, negative_emo_pickle,  NEGATIVE_TRAIN_BASE_PATH, \n",
    "                NEGATIVE_TRAIN_FACES_BASE_PATH, NEGATIVE_DUMP_TRAIN_BASE_PATH, \n",
    "                NEGATIVE_DUMP_TRAIN_FACES_BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_coord_pickle = pickle.load(open('positive_details_validation_data.obj', 'rb'))\n",
    "positive_emo_pickle = pickle.load(open('validate_positive_predictions.pkl', 'rb'))\n",
    "\n",
    "process_pickles(positive_coord_pickle, positive_emo_pickle, POSITIVE_VALIDATE_BASE_PATH, \n",
    "                POSITIVE_VALIDATE_FACES_BASE_PATH, POSITIVE_DUMP_VALIDATE_BASE_PATH, \n",
    "                POSITIVE_DUMP_VALIDATE_FACES_BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "negative_coord_pickle = pickle.load(open('negative_details_validation_data.obj', 'rb'))\n",
    "negative_emo_pickle = pickle.load(open('validate_negative_predictions.pkl', 'rb'))\n",
    "\n",
    "process_pickles(negative_coord_pickle, negative_emo_pickle, NEGATIVE_VALIDATE_BASE_PATH, \n",
    "                NEGATIVE_VALIDATE_FACES_BASE_PATH, NEGATIVE_DUMP_VALIDATE_BASE_PATH, \n",
    "                NEGATIVE_DUMP_VALIDATE_FACES_BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read memory footprint\n",
    "# hp.heap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_coord_pickle = pickle.load(open('neutral_details_validation_data.obj', 'rb'))\n",
    "neutral_emo_pickle = pickle.load(open('validate_neutral_predictions.pkl', 'rb'))\n",
    "\n",
    "process_pickles(neutral_coord_pickle, neutral_emo_pickle, NEUTRAL_VALIDATE_BASE_PATH, \n",
    "                NEUTRAL_VALIDATE_FACES_BASE_PATH, NEUTRAL_DUMP_VALIDATE_BASE_PATH, \n",
    "                NEUTRAL_DUMP_VALIDATE_FACES_BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "coord_pickle = pickle.load(open('details_test_data_new.obj', 'rb'))\n",
    "emo_pickle = pickle.load(open('test_predictions.pkl', 'rb'))\n",
    "\n",
    "process_pickles(coord_pickle, emo_pickle, NEGATIVE_TEST_BASE_PATH, \n",
    "                NEGATIVE_TEST_FACES_BASE_PATH, NEGATIVE_DUMP_TEST_BASE_PATH, \n",
    "                NEGATIVE_DUMP_TEST_FACES_BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper data\n",
    "coord_pickle = pickle.load(open('paper_data.obj', 'rb'))\n",
    "emo_pickle = pickle.load(open('paper_predictions.pkl', 'rb'))\n",
    "\n",
    "process_pickles(coord_pickle, emo_pickle, 'Data/pics/pics', \n",
    "                'Data/pics/faces', 'Data/pics/combined_heatmap', \n",
    "                'Data/pics/indi_heat_maps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
